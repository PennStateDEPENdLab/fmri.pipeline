#' Main worker function for setting up an analysis pipeline
#'
#' @param analysis_name A character string providing a useful name for identifying this analysis. Practically, this
#'   influences the top-level folder name of the group analysis outputs, as well as the name of .RData objects
#'   saved by this function to the working directory for the analysis.
#' @param scheduler Which HPC scheduler system should be used for queueing jobs. Options are 'slurm' or 'torque'.
#' @param subject_data A data.frame containing all subject-level data such as age, sex, or other covariates. Columns
#'   from \code{subject_data} can be used as covariates in group (aka 'level 3') analyses. If \code{NULL}, then
#'   this will be distilled from \code{trial_data} by looking for variables that vary at the same
#'   level as \code{variable_mapping["id"]}.
#' @param run_data A data.frame containing all run-level data such as run condition or run number. Columns from
#'   \code{run_data} can be used as covariates in subject (aka 'level 2') analyses. If \code{NULL}, this will be
#'   distilled from \code{trial_data} by looking for variables that vary at the same level as \code{variable_mapping["run"]}.
#' @param trial_data A data.frame containing trial-level statistics for all subjects. Data should be stacked in long
#'   form such that each row represents a single trial for a given subject and the number of total rows is subjects x trials.
#'   If you wish, you can pass a single trial-level data frame that also contains all run-level and subject-level covariates
#'   (i.e., a combined long format, where variables at different levels are all included as columns). In this case,
#'   \code{setup_glm_pipeline} will detect which variables occur at each level and parse these accordingly into
#'   \code{subject_data} and \code{run_data}.
#' @param variable_mapping A named character vector containing key identifying columns in \code{subject_data} and
#'   \code{trial_data}. Minimally, this vector should contain the elements 'id' 
#' @param id_column A character string indicating the name of the subject identifier in \code{subject_data} and \code{trial_data}.
#' @param bad_ids An optional vector of ids in \code{subject_data} and \code{trial_data} that should be excluded from analysis.
#' @param mr_dir_column A character string indicating the column name in \code{subject_data} containing the folder for each
#'   subject's data. Default is "mr_dir".
#' @param fmri_file_regex A character string containing a Perl-compatible regular expression 
#' @param tr The repetition time of the scanning sequence in seconds. Used for setting up design matrices
#' @param working_directory The working directory for all configuration and job submission files for this analysis.
#'   Default is a subfolder called "glm_out" in the current working directory.
#' @param drop_volumes The number of volumes to drop from the fMRI data and convolved regressors prior to analysis.
#'   Default is 0.
#' @param use_preconvolve A boolean indicating whether to enter convolved regressors into the GLM estimation software
#'   (e.g., FSL FILM/FEAT). If \code{TRUE}, all regressors will be generated by build_design_matrix in the dependlab
#'   R package. If \code{FALSE}, onset-duration-value timing will be entered and convolution will be handled internally
#'   by the GLM software. I recommend \code{TRUE} for consistency.
#' @param l1_model_variants A list of model specifications for the level 1 (aka run-level) voxelwise GLM analyses.
#'   Each element is a vector of regressors to be included in the convolved regressors of a level 1 GLM design matrix.
#'   List elements can be named for internal cross-referencing with l1_contrasts so that specific models can be paired
#'   with contrasts that test combinations of the explanatory variables in the model.
#' @param l1_contrasts An optional list of contrasts to be included in level 1 (aka run-level) voxelwise GLM analyses.
#'   Elements should be named, and names should match a single model in \code{l1_model_variants} so that models and
#'   contrasts can be combined properly to form contrasts of parameter estimates (COPEs in FSL-speak).
#' @param l1_include_diagonal_contrasts A boolean indicating whether a contrast representing each regressor alone
#'   should be added to the l1 contrast matrix for each model. This is a good idea in general so that FSL generates
#'   a COPE for each explanatory variable (EV) in the model, which allows you to examine simple group maps. If this is
#'   set to \code{FALSE}, then you will be on the hook to provide all contrasts for each model in \code{l1_contrasts}.
#' @param l2_model_variants A list of model specifications for the level 2 (aka subject-level) voxelwise GLM analyses.
#'   Each element is a vector of regressors to be included in the subject model design matrix (i.e., overall
#'   effects of run-level betas for this subject). List elements can be named for internal cross-referencing
#'   with \code{l2_contrasts} so that specific models can be paired with contrasts that test combinations of
#'   the explanatory variables in the model. If not passed, an intercept-only model will be fit at subject level. If
#'   there is only one run per subject, a second-level model will not be fit since run-level aggregation is irrelevant.
#' @param l2_contrasts An optional list of contrasts to be included in level 2 (aka subjet-level) voxelwise GLM analyses.
#'   Elements should be named, and names should match a single model in \code{l2_model_variants} so that models and
#'   contrasts can be combined properly to form contrasts of parameter estimates (COPEs in FSL-speak).
#' @param l3_model_variants A list of model specifications for the level 3 (aka group-level) voxelwise GLM analyses.
#'   Each element is a vector of regressors to be included in the group model design matrix (i.e., overall
#'   effects of lower-level betas in the sample). List elements can be named for internal cross-referencing with \code{l3_contrasts}
#'   so that specific models can be paired with contrasts that test combinations of the explanatory variables in the model.
#' @param l3_contrasts An optional list of contrasts to be included in level 3 (aka group-level) voxelwise GLM analyses.
#'   Elements should be named, and names should match a single model in \code{l3_model_variants} so that models and
#'   contrasts can be combined properly to form contrasts of parameter estimates (COPEs in FSL-speak).
#'
#' @param glm_software Which fMRI analysis package to use in the analysis. Options are "FSL", "SPM", or "AFNI"
#'   (case insensitive).
#' @param additional A list of additional metadata that will be added to the \code{glm.pipeline} object returned
#'   by the function. This can be useful if there are other identifiers that you want for long-term storage or
#'   off-shoot functions.
#'
#' @importFrom checkmate assert_subset assert_data_frame assert_number assert_integerish assert_list assert_logical
setup_glm_pipeline <- function(analysis_name="glm_analysis", scheduler="slurm", working_directory=file.path(getwd(), "glm_out"),
                               subject_data=NULL, run_data=NULL, trial_data=NULL,
                               variable_mapping=c(id="id", run="run", trial="trial", run_trial="trial", mr_dir="mr_dir"),
                               bad_ids=NULL,
                               fmri_file_regex=".*\\.nii\\.gz", tr=NULL, nuisance_file_regex=NULL, nuisance_file_columns=NULL,
                               drop_volumes=0L,
                               l1_model_variants=NULL, l1_contrasts=NULL, l1_include_diagonal_contrasts=TRUE,
                               l2_model_variants=NULL, l2_contrasts=NULL, l2_include_diagonal_contrasts=TRUE,
                               l3_model_variants=NULL, l3_contrasts=NULL, l3_include_diagonal_contrasts=TRUE,                               
                               glm_software="fsl",
                               use_preconvolve=TRUE, 
                               additional=list()) {
  
  checkmate::check_character(analysis_name)
  checkmate::assert_subset(scheduler, c("slurm", "sbatch", "torque", "qsub"), empty.ok=FALSE)
  checkmate::assert_data_frame(subject_data, null.ok=TRUE)
  checkmate::assert_data_frame(run_data, null.ok=TRUE)
  checkmate::assert_data_frame(trial_data)
  checkmate::assert_character(variable_mapping)
  checkmate::assert_number(tr)
  checkmate::assert_integerish(drop_volumes)
  checkmate::assert_list(l1_model_variants)
  checkmate::assert_list(l1_contrasts, null.ok=TRUE)
  checkmate::assert_logical(l1_include_diagonal_contrasts)
  checkmate::assert_character(glm_software)

  glm_software <- tolower(glm_software)
  checkmate::assert_subset(glm_software, c("fsl", "spm", "afni"))
  
  #setup working directory, if needed
  if (!dir.exists(working_directory)) {
    message("Setting up working directory for pipeline: ", working_directory)
    dir.create(working_directory, recursive=TRUE)
  }

  #whether to run a 2-level or 3-level analysis
  multi_run <- ifelse(length(unique(trial_data[[ variable_mapping["run"] ]])) > 1L, TRUE, FALSE)
  
  #create run data, if needed
  if (is.null(run_data) && isTRUE(multi_run)) {
    message("Distilling run_data object from trial_data by finding variables that vary at run level")

    variation_df <- trial_data %>% group_by(across(variable_mapping[c("id", "run")])) %>%
      mutate_at(vars(everything()), ~length(unique(.))) %>%
      ungroup()

    #should include the id and run columns
    one_cols <- names(which(sapply(variation_df, function(col) { all(col==1) }) ==TRUE))

    message("Retaining columns: ", paste(one_cols, collapse=", "))

    #at present, this will keep all subject-levle covariates, too. Maybe correct later?
    run_data <- trial_data %>% select(!!one_cols) %>%
      group_by(across(variable_mapping["id"])) %>%
      filter(row_number() == 1) %>% ungroup()    
    
  }

  #create subject data 
  if (is.null(subject_data)) {
    message("Distilling subject_data object from trial_data by finding variables that vary at subject level")

    variation_df <- trial_data %>% group_by(across(variable_mapping["id"])) %>%
      mutate_at(vars(everything()), ~length(unique(.))) %>%
      ungroup()

    #should include the id column itself
    one_cols <- names(which(sapply(variation_df, function(col) { all(col==1) }) ==TRUE))

    message("Retaining columns: ", paste(one_cols, collapse=", "))
    
    subject_data <- trial_data %>% select(!!one_cols) %>%
      group_by(across(variable_mapping["id"])) %>%
      filter(row_number() == 1) %>% ungroup()    
  }
  
  gma <- list(
    #metadata
    analysis_name=analysis_name,
    scheduler=scheduler,
    working_directory=working_directory,
    subject_data=subject_data,
    trial_data=trial_data,
    variable_mapping=variable_mapping,
    bad_ids=bad_ids,
    multi_run=multi_run, #2- or 3-level analysis
    
    #l1 analysis details
    fmri_file_regex=fmri_file_regex,
    nuisance_file_regex=nuisance_file_regex,
    nuisance_file_columns=nuisance_file_columns,    
    drop_volumes=drop_volumes,
    use_preconvolve=use_preconvolve,
    l1_model_variants=l1_model_variants,
    l1_contrasts=l1_contrasts,
    l1_include_diagonal_contrasts=l1_include_diagonal_contrasts,

    #l2 analysis details
    l2_model_variants=l2_model_variants,
    l2_contrasts=l2_contrasts,
    l2_include_diagonal_contrasts=l2_include_diagonal_contrasts,

    #l3 analysis details
    l3_model_variants=l3_model_variants,
    l3_contrasts=l3_contrasts,
    l3_include_diagonal_contrasts=l3_include_diagonal_contrasts
    
  )

  #validate and populate any other pipeline details before execution
  fsl_model_arguments <- finalize_pipeline_configuration(fsl_model_arguments)
}

setup_glm_pipeline(analysis_name="testing", scheduler="slurm", working_directory = tempdir(),
  subject_data=NULL, run_data=NULL, trial_data=trial_df,
  tr=1.0, nuisance_file_regex = "confounds.txt",
  l1_model_variants=list(
    entropy=c("clock", "feedback", "v_entropy"),
    value=c("clock", "feedback", "v_chosen")
  )
)

l1_mods <- list(
  l1_model_variants=list(
  )
)

#' helper function to build an l1 model specification interactively
#'
#' @param trial_data a subjects x trials data frame containing all signals to model at L1 in fMRI
#'
#' @export
#' 
build_l1_model <- function(trial_data, variable_mapping=c(id="id", run="run", trial="trial", run_trial="trial", mr_dir="mr_dir"),
                           onset_cols=NULL, parametric_cols=NULL, signal_names=NULL, event_regex=".*(onset|time).*", duration_regex=".*duration.*") {

  #maybe allow glm object to be passed in that would have trial_data and variable_mapping. I guess that would be like "add_l1_model"
  checkmate::assert_data_frame(trial_data)
  checkmate::assert_subset(onset_cols, names(trial_data)) #make sure that all event columns are in the data frame

  possible_cols <- names(trial_data)
  possible_cols <- possible_cols[!names(possible_cols) %in% variable_mapping]
  
  if (is.null(onset_cols)) {
    reselect <- 2
    onset_cols <- c()
    while(reselect==2) {
      onset_cols <- select.list(names(trial_data), multiple=TRUE, preselect=onset_cols,
        title="Choose all columns denoting event onset times\n(Command/Control-click to select multiple)")
      cat("The following columns were chosen as event onset times.\n  These will be used as onset time options for each regressor.\n\n")
      cat("  ", paste(onset_cols, collapse=", "), "\n\n")

      reselect <- menu(c("Yes", "No (reselect events)"), title="Are you done selecting all event onset times?")
    }
  }

  #basal data frame for each event
  metadata_df <- trial_data %>% dplyr::select(!!variable_mapping[c("id", "run", "run_trial")]) %>%
    setNames(c("id", "run", "trial"))
  
  #build a list of data frames, one per event (to be rbind'ed later)
  event_list <- lapply(onset_cols, function(xx) {
    metadata_df %>% bind_cols(trial_data %>% select(xx) %>% setNames("onset") %>% mutate(event=xx))
  }) %>% setNames(onset_cols)
      
  #handle durations
  for (oo in onset_cols) {
    cat("Specify a duration value or column for the event onset: ", oo, "\n")
    choices <- c("Specify fixed duration", names(trial_data))
    oval <- menu(choices=choices)
    if (oval==1) {
      duration <- as.numeric(readline(paste0("Enter the duration value (in seconds) for ", oo, ": ")))
      checkmate::assert_number(duration, na.ok=FALSE, lower=0, upper=1000)
      if (duration > 50) { warning("Duration more than 50s specified. Make sure that your durations are in seconds, not milliseconds!") }
      event_list[[oo]] <- event_list[[oo]] %>% mutate(duration=duration)
    } else {
      event_list[[oo]] <- event_list[[oo]] %>% mutate(duration=trial_data[[ choices[oval] ]])
      if (any(event_list[[oo]]$duration > 50)) {
        warning("A duration of more than 50s found in ", choices[oval], ". Make sure that your durations are in seconds, not milliseconds!")
      }
    }
  }
    
  cat("Now, we will build up signals of interest\n")
  #handle signals
  signal_list <- list()
  if (is.null(signal_names)) {
    while (TRUE) {
      this_entry <- readline("Enter the name of the signal (press RETURN to finish entry): ")
      if (this_entry=="") {
        break  #end loop
      } else {
        signal_list[[make.names(this_entry)]] <- list(name=this_entry)
      }      
    }
  } else {
    for (nn in signal_names) {
      signal_list[[make.names(nn)]] <- list(name=nn)
    }
  }
   
  for (ss in signal_list) {
    this_name <- ss$name
    cat("Choose an event with which ", this_name, " is aligned\n")
    oval <- menu(choices=onset_cols)
    this_event <- onset_cols[oval]
    
    cat("Choose the height/value of ", this_name, ".\nThe unit regressor is standard for simple stimulus onset\n")
    choices <- c("Unit regressor (1.0)", names(trial_data))
    oval <- menu(choices=choices)
    this_value <- ifelse(oval==1, 1.0, trial_data %>% select(!!oval, !!variable_mapping[c("id", "run", "run_trial")]))
    
    cat("Choose the HRF normalization method for ", this_name, ": \n")
    oval <- menu(choices=c("none", "durmax_1 (normalize HRF max to 1.0 for long events)", "evtmax_1 (normalize HRF for each event to 1.0)"))
    this_normalization <- switch(oval, `1`="none", `2`="durmax_1", `3`="evtmax_1")
    
    cat("Rescale ", this_name, " to max of 1.0 after convolution? \n")
    oval <- menu(choices=c("No", "Yes"))
    this_convmax <- ifelse(oval==1, FALSE, TRUE)
    
    cat("Should ", this_name, " be a beta series regressor (one regressor per trial)?\n")
    oval <- menu(choices=c("No", "Yes"))
    this_bs <- ifelse(oval==1, FALSE, TRUE)
    
    this_signal <- list(
      event=this_event,
      value=this_value,
      normalization=this_normalization,
      convmax_1=this_convmax,
      beta_series=this_bs
    )
    
    signal_list[[this_entry]] <- this_signal
     
  }
  

  l1_obj <- list(
    events=event_list,
    signals=signal_list
  )
  
  return(l1_obj)
}

trial_df <- readRDS("/Users/hallquist/Data_Analysis/clock_analysis/fmri/mmy3_trial_df_selective_groupfixed.rds")
build_l1_model(trial_df, onset_cols = c("clock_onset", "feedback_onset"))
  signals = c("clock", "feedback", "pe_max"))
