#' Main worker function for setting up an analysis pipeline
#'
#' @param analysis_name A character string providing a useful name for identifying this analysis. Practically, this
#'   influences the top-level folder name of the group analysis outputs, as well as the name of .RData objects
#'   saved by this function to the working directory for the analysis.
#' @param scheduler Which HPC scheduler system should be used for queueing jobs. Options are 'slurm' or 'torque'.
#' @param subject_data A data.frame containing all subject-level data such as age, sex, or other covariates. Columns
#'   from \code{subject_data} can be used as covariates in group (aka 'level 3') analyses. If \code{NULL}, then
#'   this will be distilled from \code{trial_data} by looking for variables that vary at the same
#'   level as \code{vm["id"]}.
#' @param run_data A data.frame containing all run-level data such as run condition or run number. Columns from
#'   \code{run_data} can be used as covariates in subject (aka 'level 2') analyses. If \code{NULL}, this will be
#'   distilled from \code{trial_data} by looking for variables that vary at the same level as \code{vm["run"]}.
#' @param trial_data A data.frame containing trial-level statistics for all subjects. Data should be stacked in long
#'   form such that each row represents a single trial for a given subject and the number of total rows is subjects x trials.
#'   If you wish, you can pass a single trial-level data frame that also contains all run-level and subject-level covariates
#'   (i.e., a combined long format, where variables at different levels are all included as columns). In this case,
#'   \code{setup_glm_pipeline} will detect which variables occur at each level and parse these accordingly into
#'   \code{subject_data} and \code{run_data}.
#' @param vm A named character vector containing key identifying columns in \code{subject_data} and
#'   \code{trial_data}. Minimally, this vector should contain the elements 'id' 
#' @param id_column A character string indicating the name of the subject identifier in \code{subject_data} and \code{trial_data}.
#' @param bad_ids An optional vector of ids in \code{subject_data} and \code{trial_data} that should be excluded from analysis.
#' @param mr_dir_column A character string indicating the column name in \code{subject_data} containing the folder for each
#'   subject's data. Default is "mr_dir".
#' @param fmri_file_regex A character string containing a Perl-compatible regular expression for the subfolder and filename
#'   within the \code{mr_dir} field in \code{subject_data}.
#' @param tr The repetition time of the scanning sequence in seconds. Used for setting up design matrices
#' @param working_directory The working directory for all configuration and job submission files for this analysis.
#'   Default is a subfolder called "glm_out" in the current working directory.
#' @param drop_volumes The number of volumes to drop from the fMRI data and convolved regressors prior to analysis.
#'   Default is 0.
#' @param use_preconvolve A boolean indicating whether to enter convolved regressors into the GLM estimation software
#'   (e.g., FSL FILM/FEAT). If \code{TRUE}, all regressors will be generated by build_design_matrix in the dependlab
#'   R package. If \code{FALSE}, onset-duration-value timing will be entered and convolution will be handled internally
#'   by the GLM software. I recommend \code{TRUE} for consistency.
#' @param l1_models An \code{l1_model_set} object containing all level 1 models to be included in GLM pipeline.
#'   If "prompt" is passed, \code{setup_glm_pipeline} will call \code{build_l1_models} to setup l1 models
#'   interactively. Optionally, this argument can be \code{NULL} if you want to setup l1 models later, though
#'   the resulting object will not be functional within the pipeline until l1 models are provided.
#' @param l2_model_variants A list of model specifications for the level 2 (aka subject-level) voxelwise GLM analyses.
#'   Each element is a vector of regressors to be included in the subject model design matrix (i.e., overall
#'   effects of run-level betas for this subject). List elements can be named for internal cross-referencing
#'   with \code{l2_contrasts} so that specific models can be paired with contrasts that test combinations of
#'   the explanatory variables in the model. If not passed, an intercept-only model will be fit at subject level. If
#'   there is only one run per subject, a second-level model will not be fit since run-level aggregation is irrelevant.
#' @param l2_contrasts An optional list of contrasts to be included in level 2 (aka subjet-level) voxelwise GLM analyses.
#'   Elements should be named, and names should match a single model in \code{l2_model_variants} so that models and
#'   contrasts can be combined properly to form contrasts of parameter estimates (COPEs in FSL-speak).
#' @param l3_model_variants A list of model specifications for the level 3 (aka group-level) voxelwise GLM analyses.
#'   Each element is a vector of regressors to be included in the group model design matrix (i.e., overall
#'   effects of lower-level betas in the sample). List elements can be named for internal cross-referencing with \code{l3_contrasts}
#'   so that specific models can be paired with contrasts that test combinations of the explanatory variables in the model.
#' @param l3_contrasts An optional list of contrasts to be included in level 3 (aka group-level) voxelwise GLM analyses.
#'   Elements should be named, and names should match a single model in \code{l3_model_variants} so that models and
#'   contrasts can be combined properly to form contrasts of parameter estimates (COPEs in FSL-speak).
#' @param glm_software Which fMRI analysis package to use in the analysis. Options are "FSL", "SPM", or "AFNI"
#'   (case insensitive).
#' @param additional A list of additional metadata that will be added to the \code{glm.pipeline} object returned
#'   by the function. This can be useful if there are other identifiers that you want for long-term storage or
#'   off-shoot functions.
#'
#' @importFrom checkmate assert_subset assert_data_frame assert_number assert_integerish assert_list assert_logical
#'    test_string test_class
setup_glm_pipeline <- function(analysis_name="glm_analysis", scheduler="slurm", working_directory=file.path(getwd(), "glm_out"),
                               group_output_directory="default",
                               subject_data=NULL, run_data=NULL, trial_data=NULL,
                               vm=c(id="id", session="session", run="run", trial="trial", run_trial="trial", mr_dir="mr_dir", run_nifti="run_nifti"),
                               bad_ids=NULL, tr=NULL,
                               fmri_file_regex=".*\\.nii(\\.gz)?", fmri_path_regex=NULL, run_number_regex=".*run-*([0-9]+).*",
                               nuisance_file_regex=".*confounds.*\\.txt", nuisance_file_columns=NULL, motion_params_regex="motion\\.par",
                               drop_volumes=0L, l1_models="prompt",
                               l2_model_variants=NULL, l2_contrasts=NULL, l2_include_diagonal_contrasts=TRUE,
                               l3_model_variants=NULL, l3_contrasts=NULL, l3_include_diagonal_contrasts=TRUE,
                               glm_software="fsl",
                               use_preconvolve=TRUE, truncate_runs=FALSE, force_l1_creation=FALSE,
                               motion_controls=list(
                                 exclude_run=expression(mean(FD) > 0.9 | max(FD) > 0.5),
                                 exclude_subject=expression(nruns < 4),
                                 spike_volume=expression(FD > 0.9)
                               ),
                               parallel=list(
                                 l1_setup_cores = 1L, #number of cores used when looping over l1 setup of design matrices and syntax for each subject
                                 pipeline_cores = "default" #number of cores used  when looping over l1 model variants in push_pipeline
                               ), additional=list()) {
  
  checkmate::assert_string(analysis_name) #must be scalar string
  checkmate::assert_subset(scheduler, c("slurm", "sbatch", "torque", "qsub"), empty.ok=FALSE)
  checkmate::assert_data_frame(subject_data, null.ok=TRUE)
  checkmate::assert_data_frame(run_data, null.ok=TRUE)
  checkmate::assert_data_frame(trial_data)
  checkmate::assert_character(vm)
  checkmate::assert_number(tr)
  checkmate::assert_string(fmri_file_regex, null.ok=TRUE)
  checkmate::assert_string(run_number_regex, null.ok=TRUE)
  checkmate::assert_string(nuisance_file_regex, null.ok=TRUE)
  checkmate::assert_integerish(drop_volumes)
  checkmate::assert_character(glm_software)
  checkmate::assert_logical(use_preconvolve, null.ok=FALSE)
  checkmate::assert_logical(truncate_runs, null.ok=FALSE)
  checkmate::assert_logical(force_l1_creation, null.ok=FALSE)

  glm_software <- tolower(glm_software)
  checkmate::assert_subset(glm_software, c("fsl", "spm", "afni"))
  
  #setup working directory, if needed
  if (!dir.exists(working_directory)) {
    message("Setting up working directory for pipeline: ", working_directory)
    dir.create(working_directory, recursive=TRUE)
  }

  #code default session of 1, if missing
  if (!vm["session"] %in% names(trial_data)) { trial_data[[ vm["session"] ]] <- 1 }
  
  #code default run of 1, if missing
  if (!vm["run"] %in% names(trial_data)) { trial_data[[ vm["run"] ]] <- 1 }

  #enforce id column in trial_data
  stopifnot(vm["id"] %in% names(trial_data))
  
  #whether to run a 2-level or 3-level analysis
  multi_run <- ifelse(length(unique(trial_data[[ vm["run"] ]])) > 1L, TRUE, FALSE)

  #create run data, if needed
  if (is.null(run_data) && isTRUE(multi_run)) {
    message("Distilling run_data object from trial_data by finding variables that vary at run level")

    variation_df <- trial_data %>% group_by(across(vm[c("id", "session", "run")])) %>%
      mutate_at(vars(everything()), ~length(unique(.))) %>%
      ungroup()

    #should include the id and run columns
    one_cols <- names(which(sapply(variation_df, function(col) { all(col==1) }) ==TRUE))

    message("Retaining columns: ", paste(one_cols, collapse=", "))

    #at present, this will keep all subject-level covariates, too. Maybe correct later?
    run_data <- trial_data %>% select(!!one_cols) %>%
      group_by(across(vm[c("id", "session", "run")])) %>%
      filter(row_number() == 1) %>% ungroup()    
    
  } else {
    stopifnot(vm["id"] %in% names(run_data))
    if (!vm["session"] %in% names(run_data)) { run_data[[ vm["session"] ]] <- 1 }
  }

  #create subject data 
  if (is.null(subject_data)) {
    message("Distilling subject_data object from trial_data by finding variables that vary at subject level")

    variation_df <- trial_data %>% group_by(across(vm[c("id", "session")])) %>%
      mutate_at(vars(everything()), ~length(unique(.))) %>%
      ungroup()

    #should include the id column itself
    one_cols <- names(which(sapply(variation_df, function(col) { all(col==1) }) == TRUE))

    message("Retaining columns: ", paste(one_cols, collapse=", "))
    
    subject_data <- trial_data %>% select(!!one_cols) %>%
      group_by(across(vm[c("id", "session")])) %>%
      filter(row_number() == 1) %>% ungroup()    
  }

  #can't really get traction without this!
  stopifnot(vm["mr_dir"] %in% names(subject_data))
  
  if (!is.null(l1_models)) {
    if (checkmate::test_string(l1_models) && l1_models[1L] == "prompt") {
      l1_models <- build_l1_models(trial_data, variable_mapping=vm)
    } else if (!checkmate::test_class(l1_models, "l1_model_set")) {
      stop("l1_models argument is not of class l1_model_set. Use build_l1_model to create this.")
    }
  } # else allow nulls in case user wants to specify things later
  
  gpa <- list(
    #metadata
    analysis_name=analysis_name,
    scheduler=scheduler,
    working_directory=working_directory,
    subject_data=subject_data,
    run_data=run_data,
    trial_data=trial_data,
    vm=vm,
    bad_ids=bad_ids,
    multi_run=multi_run, #2- or 3-level analysis
    truncate_runs=truncate_runs,
    force_l1_creation=force_l1_creation,
    
    #l1 analysis details
    fmri_file_regex=fmri_file_regex,
    fmri_path_regex=fmri_path_regex,
    nuisance_file_regex=nuisance_file_regex,
    nuisance_file_columns=nuisance_file_columns,
    run_number_regex=run_number_regex,
    drop_volumes=drop_volumes,
    use_preconvolve=use_preconvolve,
    l1_models=l1_models,

    #l2 analysis details
    l2_model_variants=l2_model_variants,
    l2_contrasts=l2_contrasts,
    l2_include_diagonal_contrasts=l2_include_diagonal_contrasts,

    #l3 analysis details
    l3_model_variants=l3_model_variants,
    l3_contrasts=l3_contrasts,
    l3_include_diagonal_contrasts=l3_include_diagonal_contrasts
    
  )

  #validate and populate any other pipeline details before execution
  gpa <- finalize_pipeline_configuration(gpa)

  class(gpa) <- c("list", "glm_pipeline_arguments")
  return(gpa)
}


