#' This function specifies a first-level GLM model in FSL based on a build_design_matrix
#'   bdm object.
#'
#' @param d_obj a single-subject design matrix object generated by build_design_matrix
#' @param gpa a gpa (glm_pipeline_arguments) object generated by setup_glm_pipeline
#' @param model_name a string indicating the model name within \code{gpa} to setup. If
#'   you wish to setup multiple models, this is handled upstream in setup_l1_models.R
#' @param run_nifti an optional character vector of NIfTI filenames used in l1 analysis.
#'   Prefer to pass these via the build_design_matrix object in $run_4d_files
#'
#' @importFrom checkmate assert_class assert_string assert_character assert_file_exists
#' @importFrom lgr get_logger
#' @importFrom parallel clusterApply stopCluster makeForkCluster
#' @author Michael Hallquist
#' @export
#'
fsl_l1_model <- function(
  id=NULL, session=NULL, d_obj, gpa, model_name=NULL, run_nifti=NULL, nvoxels=NULL, execute_feat=FALSE) {

  checkmate::assert_scalar(id, null.ok = FALSE)
  checkmate::assert_scalar(session, null.ok = FALSE)
  checkmate::assert_class(d_obj, "bdm")
  checkmate::assert_class(gpa, "glm_pipeline_arguments")
  checkmate::assert_string(model_name) # single string
  if (is.null(nvoxels)) { nvoxels <- rep(5e4, length(run_nifti)) } #arbitrarily use 50k voxels in fsf

  lg <- lgr::get_logger("glm_pipeline/l1_setup")
  if (!is.null(d_obj$run_4d_files)) {
    lg$debug("Using internal NIfTI files (run_4d_files) within d_obj for Feat level 1 setup")
    run_nifti <- d_obj$run_4d_files
  }

  stopifnot(length(run_nifti) == length(d_obj$run_volumes)) #need these to align
  checkmate::assert_character(run_nifti, null.ok=FALSE)
  checkmate::assert_file_exists(run_nifti) #all exist

  stopifnot(model_name %in% names(gpa$l1_models$models))

  #TODO use system.file to read from R package installation dir
  fsf_template <- readLines(file.path(gpa$pipeline_home, "inst", "feat_lvl1_nparam_template.fsf"))

  fsl_run_output_dir <- get_l1_directory(id = id, session = session, model_name = model_name, gpa = gpa, glm_software="fsl")

  l1_contrasts <- gpa$l1_models$models[[model_name]]$contrasts #contrast matrix for this model
  regressor_names <- gpa$l1_models$models[[model_name]]$regressors #names of regressors in design matrix for this model

  # TODO: this is not implemented and may not be necessary
  if (dir.exists(fsl_run_output_dir) &&
    file.exists(file.path(fsl_run_output_dir, "feat_l1_inputs.rds")) &&
    isFALSE(gpa$force_l1_creation)) {
    lg$info("%s exists. Skipping l1 fsf setup in fsl_l1_model().", fsl_run_output_dir)
    subj_l1_spec <- readRDS(file.path(fsl_run_output_dir, "feat_l1_inputs.rds"))
  }

  lg$info("Create l1 fsl_run_output_dir: %s", fsl_run_output_dir)
  dir.create(fsl_run_output_dir, showWarnings=FALSE) #one directory up from a given run
  timingdir <- file.path(fsl_run_output_dir, "timing_files")

  feat_l1_df <- data.frame(
    id = id, session = session, run_number = d_obj$runs_to_output, run_volumes = d_obj$run_volumes,
    run_nifti = run_nifti, l1_model = model_name, l1_feat_fsf = NA_character_, l1_feat_dir = NA_character_,
    l1_feat_dir_exists = NA_integer_, l1_feat_complete=NA_integer_, fsf_modified_date = as.POSIXct(NA),
    l1_confound_regressors = NA_character_, to_run=as.logical(NA)
  )
  all_l1_feat_fsfs <- c()

  #FSL computes first-level models on individual runs
  for (rr in seq_along(run_nifti)) {
    lg$info("Creating FSF for file: %s", run_nifti[rr])
    this_template <- fsf_template # start with default copy of template for this run

    if (!is.null(gpa$confound_settings$l1_confound_regressors)) {
      confounds <- get_l1_confounds(
        id = id, session = session,
        run_number = feat_l1_df$run_number[rr], gpa,
        drop_volumes = gpa$drop_volumes,
        last_volume = feat_l1_df$run_volumes[rr]
      )$confounds
      this_template <- gsub(".CONFOUNDS.", confounds, this_template, fixed = TRUE)
      feat_l1_df$l1_confound_regressors[rr] <- confounds
    } else { #disable confounds
      this_template <- gsub("set fmri(confoundevs) 1", "set fmri(confoundevs) 0", this_template, fixed=TRUE) #disable
      l1 <- grep("# Confound EVs text file for analysis 1", this_template, fixed = TRUE)
      l2 <- grep("set confoundev_files(1) \".CONFOUNDS.\"", this_template, fixed = TRUE)
      this_template <- this_template[-1*c(l1, l2)] #drop confound files lines
    }

    # TODO: perhaps support flexible names in the future
    l1_feat_fsf <- file.path(fsl_run_output_dir, paste0("FEAT_LVL1_run", feat_l1_df$run_number[rr], ".fsf"))
    l1_feat_dir <- file.path(fsl_run_output_dir, paste0("FEAT_LVL1_run", feat_l1_df$run_number[rr]))

    # search and replace within fsf file for appropriate sections
    # .OUTPUTDIR. is the feat output location
    # .NVOL. is the number of volumes in the run
    # .FUNCTIONAL. is the fmri data to process (sans extension)
    # .CONFOUNDS. is the confounds file for GLM
    # .TR. is the sequence TR in seconds

    this_template <- gsub(".OUTPUTDIR.", l1_feat_dir, this_template, fixed = TRUE)
    this_template <- gsub(".NVOL.", d_obj$run_volumes[rr], this_template, fixed=TRUE)
    this_template <- gsub(".FUNCTIONAL.", gsub(".nii(.gz)*$", "", run_nifti[rr]), this_template, fixed=TRUE)
    this_template <- gsub(".TR.", d_obj$tr, this_template, fixed=TRUE)
    this_template <- gsub(".NVOXELS.", nvoxels[rr], this_template, fixed=TRUE)

    #handle additional custom feat level 1 fields in fsf syntax
    if (!is.null(gpa$additional$feat_l1_args)) {
      for (ii in seq_along(gpa$additional$feat_l1_args)) {
        this_name <- names(gpa$additional$feat_l1_args)[ii]
        this_value <- gpa$additional$feat_l1_args[[ii]]
        if (length(this_value) > 1L) {
          lg$warn("feat_l1_args: Cannot handle settings with multiple values: %s. Skipping out.", this_name)
          next
        } else {
          lg$debug("Adding custom feat l1 setting: %s = %s", this_name, this_value)
          if (any(grepl(paste0("set fmri(", this_name, ")"), this_template, fixed=TRUE))) {
            lg$debug("Substituting existing value of feat l1 setting: %s", this_name)
            this_template <- gsub(paste0("(set fmri\\s*\\(", this_name, "\\))\\s*(.*)"), paste0("\\1 ", this_value),
              this_template,
              perl = TRUE
            )
          } else {
            this_template <- c(this_template, paste0("set fmri(", this_name, ") ", this_value))
          }
        }
      }
    }

    if (isTRUE(gpa$use_preconvolve)) {
      lg$info("Using preconvolved regressors in Feat level 1 analysis")
      # generate ev syntax

      #add common ingredients for preconvolved regressors
      regressors <- lapply(regressor_names, function(x) {
        list(name=x, waveform="custom_1", convolution="none",
          tempfilt=1, timing_file=file.path(timingdir, paste0("run", feat_l1_df$run_number[rr], "_", x, ".1D")))
      })

      lg$debug("dependlab::generate_fsf_lvl1_ev_syntax")
      ev_syn <- dependlab::generate_fsf_lvl1_ev_syntax(regressors)

      #creation of l1 contrast matrices, including the diagonal contrasts, now abstracted to finalize_pipeline_configuration.R
      #thus, l1_contrasts is already a contrast matrix ready to be passed to the generate_fsf_contrast_syntax function
      lg$debug("dependlab::generate_fsf_contrast_syntax")
      cmat_syn <- dependlab::generate_fsf_contrast_syntax(l1_contrasts)

      #combine all syntax
      this_template <- c(this_template, ev_syn, cmat_syn)
    } else {
      #TODO -- add back in standard 3-column FSL timing
      lg$error("No support for FSL-internal convolved yet")
      stop("cannot use FSL internal timing files right this moment...")
    }

    feat_l1_df$l1_feat_fsf[rr] <- l1_feat_fsf
    feat_l1_df$l1_feat_dir[rr] <- paste0(l1_feat_dir, ".feat") #add .feat extension, which is appended internally by FEAT
    feat_l1_df$l1_feat_dir_exists <- dir.exists(feat_l1_df$l1_feat_dir[rr])
    feat_l1_df$fsf_modified_date[rr] <- if (file.exists(l1_feat_fsf)) file.info(l1_feat_fsf)$mtime else as.POSIXct(NA)

    if (dir.exists(l1_feat_dir) && file.exists(file.path(l1_feat_dir, ".feat_complete"))) {
      l1_feat_complete <- readLines(file.path(l1_feat_dir, ".feat_complete"))[2]
    } else {
      l1_feat_complete <- NA_character_
    }
    feat_l1_df$l1_feat_complete[rr] <- l1_feat_complete

    if (!dir.exists(feat_l1_df$l1_feat_dir[rr]) || is.na(l1_feat_complete)) {
      feat_l1_df$to_run[rr] <- TRUE
    } else {
      feat_l1_df$to_run[rr] <- FALSE
    }

    #skip re-creation of FSF and do not run below unless force_l1_creation==TRUE
    if (file.exists(l1_feat_fsf) && isFALSE(gpa$force_l1_creation)) {
      lg$info("Skipping existing feat fsf file: %s", l1_feat_fsf)
      next
    }

    lg$info("Writing l1 fsf file: %s", l1_feat_fsf)
    cat(this_template, file=l1_feat_fsf, sep="\n")

    all_l1_feat_fsfs <- c(all_l1_feat_fsfs, l1_feat_fsf)
  }

  # If execute_feat is TRUE, execute feat on each fsf files at this stage,
  # using an 8-node socket cluster (since we have 8 runs).
  # If execute_feat is FALSE, just create the fsf files but don't execute the analysis
  if (isTRUE(execute_feat) && length(all_l1_feat_fsfs) > 0L) {
    nnodes <- min(length(all_l1_feat_fsfs), parallel::detectCores())
    lg$info("Starting fork cluster with %d workers", nnodes)
    cl_fork <- parallel::makeForkCluster(nnodes=nnodes)
    runfeat <- function(fsf) {
      runname <- basename(fsf)
      runFSLCommand(paste("feat", fsf), stdout=file.path(dirname(fsf), paste0("feat_stdout_", runname)),
        stderr=file.path(dirname(fsf), paste0("feat_stderr_", runname)))
    }

    lg$info("Executing all subject feat files with clusterApply")
    parallel::clusterApply(cl_fork, all_l1_feat_fsfs, runfeat)
    parallel::stopCluster(cl_fork)
  }

  return(feat_l1_df)

}
